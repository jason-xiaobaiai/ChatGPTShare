## 常见问题

### 什么是 token？

Token 是大语言模型处理信息的最小单元，它介于“字”和“词”之间。大部分情况下，你都可以使用 1 汉字 = 2 tokens 来近似估算中文聊天的中文所需 token 数。

### 什么是上下文？

在使用 GPT 用于文本生成时，它需要考虑之前输入的所有文本上下文，以生成连贯、有意义的句子。随着输入上下文的增加，GPT 生成的文本变得越来越连贯和精准。例如，如果将一篇完整的文章或段落作为输入，GPT 将能生成符合上下文连贯性的自然语言文本。因此，GPT 上下文累积得越多，生成文本的准确度和连贯性呈逐步提升趋势，但同时更长的上下文也会消耗更多的 token。

### 使用 GPT-3.5 系列模型还是 GPT-4 系列模型？

绝大部分情况下，GPT-3.5 系列模型即可满足您的日常需求，功能强大且经济高效，稳定高速，性价比最高。

GPT-4 系列模型相对 GPT-3.5 系列模型拥有更加广泛的常识和领域专业知识，能够以自然语言理解复杂的指令并准确解决困难问题。如您使用场景主要需要使用 GPT-4 系列模型处理复杂问题，可选择使用。

### 为什么 GPT-4 系列模型额度消耗这么快？

从 OpenAI API 调用定价规则中可知，在计算使用 token 时，会根据聊天时使用的模型，以及输入 / 输出的价格，进行单独定价，GPT-4 系列模型单次使用价格大概是 GPT-3.5 系列模型的 20 到 30 倍，加上每次对话要附带上历史消息，因此消耗会比使用 GPT-3.5 系列模型消耗相对较快。
